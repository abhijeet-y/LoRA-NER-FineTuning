{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "cdd8cb39",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-07-27T00:31:53.780153Z",
          "iopub.status.busy": "2025-07-27T00:31:53.779355Z",
          "iopub.status.idle": "2025-07-27T00:33:18.046247Z",
          "shell.execute_reply": "2025-07-27T00:33:18.045450Z"
        },
        "papermill": {
          "duration": 84.277329,
          "end_time": "2025-07-27T00:33:18.047829",
          "exception": false,
          "start_time": "2025-07-27T00:31:53.770500",
          "status": "completed"
        },
        "tags": [],
        "id": "cdd8cb39"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers datasets accelerate peft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3b96efba",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-27T00:33:18.098278Z",
          "iopub.status.busy": "2025-07-27T00:33:18.097966Z",
          "iopub.status.idle": "2025-07-27T00:33:27.177920Z",
          "shell.execute_reply": "2025-07-27T00:33:27.177189Z"
        },
        "papermill": {
          "duration": 9.106141,
          "end_time": "2025-07-27T00:33:27.179256",
          "exception": false,
          "start_time": "2025-07-27T00:33:18.073115",
          "status": "completed"
        },
        "tags": [],
        "id": "3b96efba"
      },
      "outputs": [],
      "source": [
        "# !pip install -U bitsandbytes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f4082d5",
      "metadata": {
        "papermill": {
          "duration": 0.025071,
          "end_time": "2025-07-27T00:33:27.230771",
          "exception": false,
          "start_time": "2025-07-27T00:33:27.205700",
          "status": "completed"
        },
        "tags": [],
        "id": "7f4082d5"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1edbaca0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-27T00:33:27.282601Z",
          "iopub.status.busy": "2025-07-27T00:33:27.282310Z",
          "iopub.status.idle": "2025-07-27T00:34:06.941389Z",
          "shell.execute_reply": "2025-07-27T00:34:06.940786Z"
        },
        "papermill": {
          "duration": 39.686749,
          "end_time": "2025-07-27T00:34:06.942721",
          "exception": false,
          "start_time": "2025-07-27T00:33:27.255972",
          "status": "completed"
        },
        "tags": [],
        "id": "1edbaca0",
        "outputId": "a3f69d0b-f362-4ccd-eca1-0a746e8224b3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-27 00:33:48.790846: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1753576429.138930      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1753576429.232907      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
          ]
        }
      ],
      "source": [
        "import ast\n",
        "import torch\n",
        "import transformers\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from transformers import BitsAndBytesConfig\n",
        "\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from peft import prepare_model_for_kbit_training\n",
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "from datasets import Dataset,load_dataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "from accelerate import Accelerator"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20eba405",
      "metadata": {
        "papermill": {
          "duration": 0.072068,
          "end_time": "2025-07-27T00:34:07.041607",
          "exception": false,
          "start_time": "2025-07-27T00:34:06.969539",
          "status": "completed"
        },
        "tags": [],
        "id": "20eba405"
      },
      "source": [
        "## Reading the data..!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74c16780",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-27T00:34:07.094266Z",
          "iopub.status.busy": "2025-07-27T00:34:07.093663Z",
          "iopub.status.idle": "2025-07-27T00:34:07.381112Z",
          "shell.execute_reply": "2025-07-27T00:34:07.380245Z"
        },
        "papermill": {
          "duration": 0.314659,
          "end_time": "2025-07-27T00:34:07.382216",
          "exception": false,
          "start_time": "2025-07-27T00:34:07.067557",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "59159505a0764e6e909265de2f567182"
          ]
        },
        "id": "74c16780",
        "outputId": "637bcea7-0dd6-47cb-b7cd-15c88a64296a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "59159505a0764e6e909265de2f567182",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset features: {'event_text': Value(dtype='string', id=None), 'output': {'action': Value(dtype='string', id=None), 'date': Value(dtype='string', id=None), 'time': Value(dtype='string', id=None), 'attendees': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'location': Value(dtype='string', id=None), 'duration': Value(dtype='string', id=None), 'recurrence': Value(dtype='string', id=None), 'notes': Value(dtype='string', id=None)}}\n",
            "Number of examples: 792\n",
            "\n",
            "First 3 examples:\n",
            "{'event_text': 'Late night study session at the café on 15th, Dec 2024 at 9:00 pm for 2 hours.', 'output': {'action': 'study session', 'date': '15/12/2024', 'time': '9:00 PM', 'attendees': None, 'location': 'café', 'duration': '2 hours', 'recurrence': None, 'notes': None}}\n",
            "{'event_text': 'Hang out at the beach on 18th, Jul 2024 around 10:00 am for 3 hours or so.', 'output': {'action': 'Hang out', 'date': '18/07/2024', 'time': '10:00 AM', 'attendees': None, 'location': 'beach', 'duration': '3 hours', 'recurrence': None, 'notes': None}}\n",
            "{'event_text': 'Business lunch at that seafood spot on 2nd, Nov 2024 at 1:00 pm for roughly 2 hours.', 'output': {'action': 'Business lunch', 'date': '02/11/2024', 'time': '1:00 PM', 'attendees': None, 'location': 'that seafood spot', 'duration': '2 hours', 'recurrence': None, 'notes': None}}\n"
          ]
        }
      ],
      "source": [
        "data_path = r\"/kaggle/input/llm-fine-tune-dataset/event_text_mapping.jsonl\"\n",
        "ds = load_dataset(\"json\", data_files=data_path)[\"train\"]\n",
        "\n",
        "print(\"Dataset features:\", ds.features)\n",
        "print(\"Number of examples:\", len(ds))\n",
        "print(\"\\nFirst 3 examples:\")\n",
        "for i in range(min(3, len(ds))):\n",
        "    print(ds[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b89693b6",
      "metadata": {
        "papermill": {
          "duration": 0.026933,
          "end_time": "2025-07-27T00:34:07.436256",
          "exception": false,
          "start_time": "2025-07-27T00:34:07.409323",
          "status": "completed"
        },
        "tags": [],
        "id": "b89693b6"
      },
      "source": [
        "### Dataset Overview and Initial Exploration\n",
        "\n",
        "We begin by loading a JSON dataset consisting of 792 examples, each containing a natural language event description and a structured `output` dictionary. The schema reveals that each event is broken down into actionable fields such as `action`, `date`, `time`, `location`, `duration`, and optional fields like `attendees`, `recurrence`, and `notes`. The initial few samples confirm the consistency in format and provide confidence that the dataset is well-suited for training models to perform structured information extraction from free-form text.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6457fce3",
      "metadata": {
        "papermill": {
          "duration": 0.026415,
          "end_time": "2025-07-27T00:34:07.488833",
          "exception": false,
          "start_time": "2025-07-27T00:34:07.462418",
          "status": "completed"
        },
        "tags": [],
        "id": "6457fce3"
      },
      "source": [
        "## Loading the model..!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9141f650",
      "metadata": {
        "papermill": {
          "duration": 0.027132,
          "end_time": "2025-07-27T00:34:07.542246",
          "exception": false,
          "start_time": "2025-07-27T00:34:07.515114",
          "status": "completed"
        },
        "tags": [],
        "id": "9141f650"
      },
      "source": [
        "### Model Loading with 4-bit Quantization\n",
        "\n",
        "We load the `SmolLM-360M` model using 4-bit NF4 quantization via `BitsAndBytesConfig` for efficient memory usage and faster inference. The model architecture is based on LLaMA with 32 decoder layers and linear projections quantized to 4-bit. This enables running a moderately sized language model on limited GPU resources without significantly compromising performance, making it ideal for experimentation or fine-tuning tasks on consumer hardware.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db67e527",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-27T00:34:07.595429Z",
          "iopub.status.busy": "2025-07-27T00:34:07.595174Z",
          "iopub.status.idle": "2025-07-27T00:34:17.081436Z",
          "shell.execute_reply": "2025-07-27T00:34:17.080677Z"
        },
        "papermill": {
          "duration": 9.514423,
          "end_time": "2025-07-27T00:34:17.082719",
          "exception": false,
          "start_time": "2025-07-27T00:34:07.568296",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "456019ab7b0f42f78b6c9fd7c5d317d4",
            "d714ca4103ff4bf39246c9ec6ebb2131",
            "385bc656a7a64120b93bdc63d6e15134"
          ]
        },
        "id": "db67e527",
        "outputId": "000ee2fa-ad2b-445d-a01b-d45af3228c9e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "456019ab7b0f42f78b6c9fd7c5d317d4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/725 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d714ca4103ff4bf39246c9ec6ebb2131",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.45G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "385bc656a7a64120b93bdc63d6e15134",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "LlamaForCausalLM(\n",
              "  (model): LlamaModel(\n",
              "    (embed_tokens): Embedding(49152, 960)\n",
              "    (layers): ModuleList(\n",
              "      (0-31): 32 x LlamaDecoderLayer(\n",
              "        (self_attn): LlamaAttention(\n",
              "          (q_proj): Linear4bit(in_features=960, out_features=960, bias=False)\n",
              "          (k_proj): Linear4bit(in_features=960, out_features=320, bias=False)\n",
              "          (v_proj): Linear4bit(in_features=960, out_features=320, bias=False)\n",
              "          (o_proj): Linear4bit(in_features=960, out_features=960, bias=False)\n",
              "        )\n",
              "        (mlp): LlamaMLP(\n",
              "          (gate_proj): Linear4bit(in_features=960, out_features=2560, bias=False)\n",
              "          (up_proj): Linear4bit(in_features=960, out_features=2560, bias=False)\n",
              "          (down_proj): Linear4bit(in_features=2560, out_features=960, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): LlamaRMSNorm((960,), eps=1e-05)\n",
              "        (post_attention_layernorm): LlamaRMSNorm((960,), eps=1e-05)\n",
              "      )\n",
              "    )\n",
              "    (norm): LlamaRMSNorm((960,), eps=1e-05)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=960, out_features=49152, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MODEL_NAME = \"HuggingFaceTB/SmolLM-360M\"\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME, quantization_config=bnb_config,device_map={\"\": 0}\n",
        ")\n",
        "\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5f3061f",
      "metadata": {
        "papermill": {
          "duration": 0.026187,
          "end_time": "2025-07-27T00:34:17.135808",
          "exception": false,
          "start_time": "2025-07-27T00:34:17.109621",
          "status": "completed"
        },
        "tags": [],
        "id": "a5f3061f"
      },
      "source": [
        "### Setting up the tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "821b498e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-27T00:34:17.189536Z",
          "iopub.status.busy": "2025-07-27T00:34:17.189288Z",
          "iopub.status.idle": "2025-07-27T00:34:18.138811Z",
          "shell.execute_reply": "2025-07-27T00:34:18.138209Z"
        },
        "papermill": {
          "duration": 0.977797,
          "end_time": "2025-07-27T00:34:18.140077",
          "exception": false,
          "start_time": "2025-07-27T00:34:17.162280",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "8fca20a6034f41c9920f77dfedf274b6",
            "ea3fa4f7aef149afa2bf1426e61a5d4c",
            "bdbf97fc5e8244deb8cdc2376fba1fe6",
            "617a7474a9c44118bec885f477f556bb",
            "dec639508b45416a8e894e59d224e7cb"
          ]
        },
        "id": "821b498e",
        "outputId": "195f6fb6-0bbe-4881-df68-9b87f3a3d74e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8fca20a6034f41c9920f77dfedf274b6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea3fa4f7aef149afa2bf1426e61a5d4c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bdbf97fc5e8244deb8cdc2376fba1fe6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "617a7474a9c44118bec885f477f556bb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dec639508b45416a8e894e59d224e7cb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/831 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bd02f78",
      "metadata": {
        "papermill": {
          "duration": 0.026644,
          "end_time": "2025-07-27T00:34:18.197615",
          "exception": false,
          "start_time": "2025-07-27T00:34:18.170971",
          "status": "completed"
        },
        "tags": [],
        "id": "0bd02f78"
      },
      "source": [
        "### Checking the text generation capability of the model..!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "678ea7d8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-27T00:34:18.252057Z",
          "iopub.status.busy": "2025-07-27T00:34:18.251761Z",
          "iopub.status.idle": "2025-07-27T00:34:20.915763Z",
          "shell.execute_reply": "2025-07-27T00:34:20.914856Z"
        },
        "papermill": {
          "duration": 2.692846,
          "end_time": "2025-07-27T00:34:20.917144",
          "exception": false,
          "start_time": "2025-07-27T00:34:18.224298",
          "status": "completed"
        },
        "tags": [],
        "id": "678ea7d8",
        "outputId": "540f4ae3-b7eb-4a52-ad09-dedcc1696dcd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: Hello, I'm Abhijeet. How are you?\n",
            "------------------------------\n",
            "Output: Hello, I'm Abhijeet. How are you?\n",
            "Abhijeet: I'm fine, thanks.\n",
            "Abhijeet: How are you?\n",
            "\n"
          ]
        }
      ],
      "source": [
        "input_text = \"Hello, I'm Abhijeet. How are you?\"\n",
        "inputs = tokenizer(input_text, return_tensors=\"pt\").to(model.device)\n",
        "outputs = model.generate(**inputs, max_new_tokens=25)\n",
        "decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "print(f\"Input: {input_text}\")\n",
        "print(\"-\"*30)\n",
        "print(f\"Output: {decoded_output}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2bb43e6",
      "metadata": {
        "papermill": {
          "duration": 0.026027,
          "end_time": "2025-07-27T00:34:20.970605",
          "exception": false,
          "start_time": "2025-07-27T00:34:20.944578",
          "status": "completed"
        },
        "tags": [],
        "id": "f2bb43e6"
      },
      "source": [
        "### Checking the output for our NER task..!\n",
        "- I validated the model's ability to learn from few-shot prompting by providing a structured example followed by a new user input.\n",
        "- The prompt design helps guide the model by setting a clear pattern to follow.\n",
        "- I observed that the model follows the example structure well, but tends to repeat parts of the prompt and occasionally truncates the response.\n",
        "- These issues hint at limitations in generalization from just in-context examples.\n",
        "- Fine-tuning the model on a larger set of such input-output JSON pairs could help it learn the structure more robustly.\n",
        "- With fine-tuning, the model would better internalize entity extraction logic and reduce over-reliance on prompt templates.\n",
        "- It would also improve consistency in output formatting, casing, and handling edge cases like ambiguous durations or varying phrasing.\n",
        "- Overall, fine-tuning can make the model more reliable, reduce prompt engineering overhead, and produce cleaner, more accurate extractions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "348ffb7c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-27T00:34:21.024105Z",
          "iopub.status.busy": "2025-07-27T00:34:21.023824Z",
          "iopub.status.idle": "2025-07-27T00:34:28.432063Z",
          "shell.execute_reply": "2025-07-27T00:34:28.431104Z"
        },
        "papermill": {
          "duration": 7.436754,
          "end_time": "2025-07-27T00:34:28.433607",
          "exception": false,
          "start_time": "2025-07-27T00:34:20.996853",
          "status": "completed"
        },
        "tags": [],
        "id": "348ffb7c",
        "outputId": "ad811d20-3ffa-4873-a703-fb83263fe462"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> PROMPT FOR THE MODEL:\n",
            "---------------------\n",
            "See the given example to extract the entities based on given input in JSON format.\n",
            "\n",
            "Example Input: Late night study session at the café on 15th, Dec 2024 at 9:00 pm for 2 hours.\n",
            "Example Output: {'action': 'study session', 'date': '15/12/2024', 'time': '9:00 PM', 'attendees': None, 'location': 'café', 'duration': '2 hours', 'recurrence': None, 'notes': None}\n",
            "--------------------------\n",
            "Please extract the entities for the below user input in JSON format. And do not output anything else.\n",
            "User Input: Hang out at the beach on 18th, Jul 2024 around 10:00 am for 3 hours or so.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            ">> RESPONSE FROM SLM:\n",
            "--------------------\n",
            "Example Output: {'action': 'hang out', 'date': '18/07/2024', 'time': '10:00 am', 'attendees': None, 'location': 'beach', 'duration': '3 hours', 'recurrence': None, 'notes': None}\n",
            "--------------------------\n",
            "Please extract the entities for the below user input in JSON format. And do not output anything else.\n",
            "User Input: Hang out at the\n",
            "\n",
            "\n",
            "\n",
            ">> ACTUAL OUTPUT:\n",
            "-----------------\n",
            "{'action': 'Hang out', 'date': '18/07/2024', 'time': '10:00 AM', 'attendees': None, 'location': 'beach', 'duration': '3 hours', 'recurrence': None, 'notes': None}\n"
          ]
        }
      ],
      "source": [
        "example = ds[0]\n",
        "question = ds[1]\n",
        "prompt_template = (\n",
        "    \"See the given example to extract the entities based on given input in JSON format.\\n\\n\"\n",
        "    \"Example Input: {event_text}\\n\"\n",
        "    \"Example Output: {output}\\n\"\n",
        "    \"--------------------------\\n\"\n",
        "    \"Please extract the entities for the below user input in JSON format. And do not output anything else.\\n\"\n",
        "    \"User Input: {user_input}\\n\"\n",
        ")\n",
        "\n",
        "formatted_example = {\n",
        "    \"text\": prompt_template.format(event_text=example['event_text'], output=example['output'],user_input=question['event_text'])\n",
        "}\n",
        "\n",
        "print(\">> PROMPT FOR THE MODEL:\")\n",
        "print(\"-\"*len(\"PROMPT FOR THE MODEL:\"))\n",
        "print(formatted_example['text'])\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "input_text = formatted_example['text']\n",
        "inputs = tokenizer(input_text, return_tensors=\"pt\").to(model.device)\n",
        "outputs = model.generate(**inputs, max_new_tokens=100)\n",
        "decoded_output = tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
        "\n",
        "# print(f\"Input: {input_text}\")\n",
        "print(\">> Response from SLM:\".upper())\n",
        "print(\"-\"*len(\">> Response from LM:\"))\n",
        "print(decoded_output)\n",
        "print(\"\\n\\n\")\n",
        "print(\">> Actual Output:\".upper())\n",
        "print(\"-\"*len(\">> Actual Output:\"))\n",
        "print(question['output'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b91bc2b9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-26T09:08:11.164425Z",
          "iopub.status.busy": "2025-07-26T09:08:11.163552Z",
          "iopub.status.idle": "2025-07-26T09:08:11.167938Z",
          "shell.execute_reply": "2025-07-26T09:08:11.167251Z",
          "shell.execute_reply.started": "2025-07-26T09:08:11.164390Z"
        },
        "papermill": {
          "duration": 0.027976,
          "end_time": "2025-07-27T00:34:28.490924",
          "exception": false,
          "start_time": "2025-07-27T00:34:28.462948",
          "status": "completed"
        },
        "tags": [],
        "id": "b91bc2b9"
      },
      "source": [
        "## Preparing the dataset for fine-tuning task..!\n",
        "- I structured the dataset using a consistent prompt-response format to guide the model during training.\n",
        "- Using `map(batched=True)` allowed efficient batch processing while embedding each input into a few-shot prompt with a fixed example.\n",
        "- The inclusion of a reference example in every prompt establishes a clear pattern for the model to imitate during fine-tuning.\n",
        "- This consistency in formatting helps the SLM (Small Language Model) learn how to extract entities reliably in the expected JSON format.\n",
        "- By retaining both the prompt (`text`) and the ground truth (`output`), I can directly train the model in a supervised manner.\n",
        "- This setup encourages the model to understand contextual clues and align its outputs closely with structured targets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "203e247e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-27T00:34:28.546622Z",
          "iopub.status.busy": "2025-07-27T00:34:28.546239Z",
          "iopub.status.idle": "2025-07-27T00:34:28.551487Z",
          "shell.execute_reply": "2025-07-27T00:34:28.550968Z"
        },
        "papermill": {
          "duration": 0.034635,
          "end_time": "2025-07-27T00:34:28.552541",
          "exception": false,
          "start_time": "2025-07-27T00:34:28.517906",
          "status": "completed"
        },
        "tags": [],
        "id": "203e247e"
      },
      "outputs": [],
      "source": [
        "def serialize(examples):\n",
        "    \"\"\"\n",
        "    Constructs a batch of prompt strings using few-shot learning format for NER-style entity extraction.\n",
        "\n",
        "    This function formats each input text in `examples['event_text']` by embedding it into a predefined\n",
        "    prompt template. It uses a fixed example (the first instance from the `raw` dataset) as a demonstration\n",
        "    to guide the model. The function returns a dictionary containing:\n",
        "\n",
        "    - \"text\": List of formatted prompt strings for each input.\n",
        "    - \"output\": Corresponding expected outputs as strings for comparison or training.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    examples : dict\n",
        "        A dictionary with two keys:\n",
        "        - 'event_text': List of user inputs to extract entities from.\n",
        "        - 'output': List of corresponding ground truth outputs in dictionary format.\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    dict\n",
        "        A dictionary with:\n",
        "        - 'text': List of formatted prompt strings.\n",
        "        - 'output': List of expected output strings.\n",
        "    \"\"\"\n",
        "\n",
        "    prompt_template = (\n",
        "    \"See the given example to extract the entities based on given input in JSON format.\\n\\n\"\n",
        "    \"Example Input: {example_event_text}\\n\"\n",
        "    \"Example Output: {example_output}\\n\"\n",
        "    \"--------------------------\\n\"\n",
        "    \"Please extract the entities for the below user input in JSON format. And do not output anything else.\\n\\n\"\n",
        "    \"Human Input: {user_input}\\n\"\n",
        "    \"AI: \"\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    # Use the first example from the raw dataset as the fixed example for the prompt\n",
        "    example_instance={}\n",
        "    example_instance[\"event_text\"] = \"\"\"Late night study session at the café on 15th, Dec 2024 at 9:00 pm for 2 hours.\"\"\"\n",
        "    example_instance['output'] = \"\"\"{'action': 'study session', 'date': '15/12/2024', 'time': '9:00 PM', 'attendees': None, 'location': 'café', 'duration': '2 hours', 'recurrence': None, 'notes': None}\"\"\"\n",
        "    formatted_texts = []\n",
        "\n",
        "\n",
        "    # Iterate through the batch using the length of one of the lists (assuming all lists have the same length)\n",
        "    for i in range(len(examples['event_text'])):\n",
        "        formatted_text = prompt_template.format(\n",
        "            example_event_text=example_instance['event_text'],\n",
        "            example_output=example_instance['output'],\n",
        "            user_input=examples['event_text'][i] # Access each example in the batch correctly\n",
        "        )\n",
        "        formatted_texts.append(formatted_text)\n",
        "\n",
        "\n",
        "    return {\"text\": formatted_texts, \"output\": [str(output) for output in examples['output']]} # Access each output in the batch correctly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66c5d5b0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-27T00:34:28.608420Z",
          "iopub.status.busy": "2025-07-27T00:34:28.608204Z",
          "iopub.status.idle": "2025-07-27T00:34:28.779670Z",
          "shell.execute_reply": "2025-07-27T00:34:28.778898Z"
        },
        "papermill": {
          "duration": 0.201623,
          "end_time": "2025-07-27T00:34:28.780703",
          "exception": false,
          "start_time": "2025-07-27T00:34:28.579080",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "5c36d0a4a13c4f4e8cbac84a94ee2f5c"
          ]
        },
        "id": "66c5d5b0",
        "outputId": "ba2a2b47-0248-4ee0-aaaf-86a4481df5f8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c36d0a4a13c4f4e8cbac84a94ee2f5c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/712 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FORMATTED DATASET EXAMPLE:\n",
            "--------------------------\n",
            "See the given example to extract the entities based on given input in JSON format.\n",
            "\n",
            "Example Input: Late night study session at the café on 15th, Dec 2024 at 9:00 pm for 2 hours.\n",
            "Example Output: {'action': 'study session', 'date': '15/12/2024', 'time': '9:00 PM', 'attendees': None, 'location': 'café', 'duration': '2 hours', 'recurrence': None, 'notes': None}\n",
            "--------------------------\n",
            "Please extract the entities for the below user input in JSON format. And do not output anything else.\n",
            "\n",
            "Human Input: Set budget meeting 13/10/2023 11:30am Conference Room 2 with Olivia, Mason, and Rachel 2hrs.\n",
            "AI: {'action': 'Set budget meeting', 'date': '13/10/2023', 'time': '11:30 AM', 'attendees': ['Olivia', 'Mason', 'Rachel'], 'location': 'Conference Room 2', 'duration': '2hrs', 'recurrence': None, 'notes': None}\n",
            "\n",
            "\n",
            "\n",
            "CORRESPONDING OUTPUT:\n",
            "---------------------\n",
            "{'action': 'Set budget meeting', 'date': '13/10/2023', 'time': '11:30 AM', 'attendees': ['Olivia', 'Mason', 'Rachel'], 'location': 'Conference Room 2', 'duration': '2hrs', 'recurrence': None, 'notes': None}\n"
          ]
        }
      ],
      "source": [
        "# Process the dataset in batches using map with batched=True\n",
        "dataset = load_dataset(\"json\", data_files=data_path)['train']\n",
        "dataset = dataset.train_test_split(test_size=0.1)\n",
        "\n",
        "ds_val = dataset['test']\n",
        "ds_train = dataset['train']\n",
        "ds_train = ds_train.map(serialize,batched=True)\n",
        "\n",
        "\n",
        "print(\"Formatted dataset example:\".upper())\n",
        "print(\"-\"*len(\"Formatted dataset example:\"))\n",
        "print(ds_train[2]['text']+ds_train[2]['output'])\n",
        "print(\"\\n\\n\")\n",
        "print(\"Corresponding output:\".upper())\n",
        "print(\"-\"*len(\"Corresponding output:\"))\n",
        "print(ds_train[2]['output'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "967bb1ab",
      "metadata": {
        "papermill": {
          "duration": 0.026662,
          "end_time": "2025-07-27T00:34:28.835109",
          "exception": false,
          "start_time": "2025-07-27T00:34:28.808447",
          "status": "completed"
        },
        "tags": [],
        "id": "967bb1ab"
      },
      "source": [
        "### Creating a `data_loader` to generate batch of training sample for fine-tuning..!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f0e2bdd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-27T00:34:28.889295Z",
          "iopub.status.busy": "2025-07-27T00:34:28.889006Z",
          "iopub.status.idle": "2025-07-27T00:34:28.894434Z",
          "shell.execute_reply": "2025-07-27T00:34:28.893807Z"
        },
        "papermill": {
          "duration": 0.033869,
          "end_time": "2025-07-27T00:34:28.895465",
          "exception": false,
          "start_time": "2025-07-27T00:34:28.861596",
          "status": "completed"
        },
        "tags": [],
        "id": "2f0e2bdd"
      },
      "outputs": [],
      "source": [
        "def tokenize_fn(example):\n",
        "\n",
        "    \"\"\"\n",
        "    Prepares tokenized input for supervised fine-tuning of a language model using prompt-response format.\n",
        "\n",
        "    This function takes a dictionary containing a prompt (`example[\"text\"]`) and a target output\n",
        "    (`example[\"output\"]`), concatenates them into a single training string, and tokenizes it using\n",
        "    the provided tokenizer. It ensures that only the target portion contributes to the training loss\n",
        "    by masking the prompt tokens with -100 in the label tensor.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    example : dict\n",
        "        A dictionary with:\n",
        "        - 'text': The input prompt string used to condition the model.\n",
        "        - 'output': The expected target string to be predicted by the model.\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    dict\n",
        "        A dictionary containing:\n",
        "        - 'input_ids': Token IDs of the concatenated prompt and target.\n",
        "        - 'attention_mask': Attention mask for the input sequence.\n",
        "        - 'labels': Token IDs with prompt tokens masked (-100) to compute loss only on the target.\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = example[\"text\"]\n",
        "    target = example[\"output\"]\n",
        "\n",
        "\n",
        "    # Concatenate prompt and expected output as training input\n",
        "    full_text = prompt + target\n",
        "    # print(f\"Full Text:\\n{full_text}\")\n",
        "\n",
        "\n",
        "    # Tokenize the full sequence\n",
        "    inputs = tokenizer(full_text, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=512)\n",
        "\n",
        "    input_ids = inputs[\"input_ids\"]\n",
        "    attention_mask = inputs[\"attention_mask\"]\n",
        "\n",
        "\n",
        "    # Create labels: only the target portion should contribute to loss\n",
        "    labels = input_ids.clone()\n",
        "    prompt_len = len(tokenizer(prompt)[\"input_ids\"])-1\n",
        "    labels[0,:prompt_len] = -100  # Mask out prompt tokens\n",
        "\n",
        "    # Final training batch\n",
        "    batch = {\n",
        "        \"input_ids\": input_ids.squeeze(1),\n",
        "        \"attention_mask\": attention_mask.squeeze(1),\n",
        "        \"labels\": labels.squeeze(1),\n",
        "        \"prompt_len\":prompt_len\n",
        "    }\n",
        "\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89e1c670",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-27T00:34:28.950159Z",
          "iopub.status.busy": "2025-07-27T00:34:28.949888Z",
          "iopub.status.idle": "2025-07-27T00:34:28.953264Z",
          "shell.execute_reply": "2025-07-27T00:34:28.952717Z"
        },
        "papermill": {
          "duration": 0.031889,
          "end_time": "2025-07-27T00:34:28.954358",
          "exception": false,
          "start_time": "2025-07-27T00:34:28.922469",
          "status": "completed"
        },
        "tags": [],
        "id": "89e1c670"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    return tokenizer.pad(batch, padding = True,return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ce02a4a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-27T00:34:29.008445Z",
          "iopub.status.busy": "2025-07-27T00:34:29.008236Z",
          "iopub.status.idle": "2025-07-27T00:34:30.244313Z",
          "shell.execute_reply": "2025-07-27T00:34:30.243495Z"
        },
        "papermill": {
          "duration": 1.264715,
          "end_time": "2025-07-27T00:34:30.245502",
          "exception": false,
          "start_time": "2025-07-27T00:34:28.980787",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "33ea72d046a248ed93d108013e29e881"
          ]
        },
        "id": "9ce02a4a",
        "outputId": "7d513f38-259b-4697-e55f-8e31329e035e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "33ea72d046a248ed93d108013e29e881",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/712 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenized_train = ds_train.map(tokenize_fn, remove_columns=ds_train.column_names)\n",
        "train_loader = DataLoader(tokenized_train, batch_size=4, shuffle=True, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c8e9a60",
      "metadata": {
        "papermill": {
          "duration": 0.027339,
          "end_time": "2025-07-27T00:34:30.302230",
          "exception": false,
          "start_time": "2025-07-27T00:34:30.274891",
          "status": "completed"
        },
        "tags": [],
        "id": "6c8e9a60"
      },
      "source": [
        "- I applied the `tokenize_fn` to the training dataset using `map`, which ensures each example is tokenized consistently.\n",
        "- Removing original columns keeps the dataset lean and avoids redundancy during training.\n",
        "- I wrapped the tokenized dataset into a `DataLoader` to enable efficient batching, shuffling, and feeding into the model.\n",
        "- The use of `collate_fn` ensures dynamic padding and batch formatting, making the training pipeline robust to variable input lengths.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "339351b8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-27T00:34:30.359199Z",
          "iopub.status.busy": "2025-07-27T00:34:30.358790Z",
          "iopub.status.idle": "2025-07-27T00:34:30.377937Z",
          "shell.execute_reply": "2025-07-27T00:34:30.377077Z"
        },
        "papermill": {
          "duration": 0.049663,
          "end_time": "2025-07-27T00:34:30.379130",
          "exception": false,
          "start_time": "2025-07-27T00:34:30.329467",
          "status": "completed"
        },
        "tags": [],
        "id": "339351b8",
        "outputId": "16dcc660-b8fd-4d5b-867b-237128a92eef"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BATCH KEYS:\n",
            "-----------\n",
            "dict_keys(['input_ids', 'attention_mask', 'labels', 'prompt_len'])\n",
            "\n",
            "\n",
            "\n",
            "-------------------------\n",
            "SAMPLE BATCH EXAMPLES:\n",
            "-------------------------\n",
            "\n",
            "\n",
            "\n",
            "------------\n",
            "EXAMPLE: 1\n",
            "------------\n",
            "See the given example to extract the entities based on given input in JSON format.\n",
            "\n",
            "Example Input: Late night study session at the café on 15th, Dec 2024 at 9:00 pm for 2 hours.\n",
            "Example Output: {'action': 'study session', 'date': '15/12/2024', 'time': '9:00 PM', 'attendees': None, 'location': 'café', 'duration': '2 hours', 'recurrence': None, 'notes': None}\n",
            "--------------------------\n",
            "Please extract the entities for the below user input in JSON format. And do not output anything else.\n",
            "\n",
            "Human Input: Plan new hire training 2024-02-05 9:15am with Mike for 2 hours.\n",
            "AI: {'action': 'Plan new hire training', 'date': '2024-02-05', 'time': '9:15 AM', 'attendees': ['Mike'], 'location': None, 'duration': '2 hours', 'recurrence': None, 'notes': None}\n",
            "\n",
            "\n",
            "OUTPUT:\n",
            "-------\n",
            " {'action': 'Plan new hire training', 'date': '2024-02-05', 'time': '9:15 AM', 'attendees': ['Mike'], 'location': None, 'duration': '2 hours', 'recurrence': None, 'notes': None}\n",
            "------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "------------\n",
            "EXAMPLE: 2\n",
            "------------\n",
            "See the given example to extract the entities based on given input in JSON format.\n",
            "\n",
            "Example Input: Late night study session at the café on 15th, Dec 2024 at 9:00 pm for 2 hours.\n",
            "Example Output: {'action': 'study session', 'date': '15/12/2024', 'time': '9:00 PM', 'attendees': None, 'location': 'café', 'duration': '2 hours', 'recurrence': None, 'notes': None}\n",
            "--------------------------\n",
            "Please extract the entities for the below user input in JSON format. And do not output anything else.\n",
            "\n",
            "Human Input: Policy discussion 13/12/2023 at 11:30am with Rachel and Luke, 1 hour.\n",
            "AI: {'action': 'Policy discussion', 'date': '13/12/2023', 'time': '11:30 AM', 'attendees': ['Rachel', 'Luke'], 'location': None, 'duration': '1 hour', 'recurrence': None, 'notes': None}\n",
            "\n",
            "\n",
            "OUTPUT:\n",
            "-------\n",
            " {'action': 'Policy discussion', 'date': '13/12/2023', 'time': '11:30 AM', 'attendees': ['Rachel', 'Luke'], 'location': None, 'duration': '1 hour', 'recurrence': None, 'notes': None}\n",
            "------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "------------\n",
            "EXAMPLE: 3\n",
            "------------\n",
            "See the given example to extract the entities based on given input in JSON format.\n",
            "\n",
            "Example Input: Late night study session at the café on 15th, Dec 2024 at 9:00 pm for 2 hours.\n",
            "Example Output: {'action': 'study session', 'date': '15/12/2024', 'time': '9:00 PM', 'attendees': None, 'location': 'café', 'duration': '2 hours', 'recurrence': None, 'notes': None}\n",
            "--------------------------\n",
            "Please extract the entities for the below user input in JSON format. And do not output anything else.\n",
            "\n",
            "Human Input: Legal review 2023-12-18 1:00 pm w/ Henry & Liz Teams 1h\n",
            "AI: {'action': 'Legal review', 'date': '2023-12-18', 'time': '1:00 PM', 'attendees': ['Henry', 'Liz'], 'location': 'Teams', 'duration': '1h', 'recurrence': None, 'notes': None}\n",
            "\n",
            "\n",
            "OUTPUT:\n",
            "-------\n",
            " {'action': 'Legal review', 'date': '2023-12-18', 'time': '1:00 PM', 'attendees': ['Henry', 'Liz'], 'location': 'Teams', 'duration': '1h', 'recurrence': None, 'notes': None}\n",
            "------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "------------\n",
            "EXAMPLE: 4\n",
            "------------\n",
            "See the given example to extract the entities based on given input in JSON format.\n",
            "\n",
            "Example Input: Late night study session at the café on 15th, Dec 2024 at 9:00 pm for 2 hours.\n",
            "Example Output: {'action': 'study session', 'date': '15/12/2024', 'time': '9:00 PM', 'attendees': None, 'location': 'café', 'duration': '2 hours', 'recurrence': None, 'notes': None}\n",
            "--------------------------\n",
            "Please extract the entities for the below user input in JSON format. And do not output anything else.\n",
            "\n",
            "Human Input: November 4, 2024 2pm leadership sync Alex, Olivia, Ryan on Skype\n",
            "AI: {'action': 'leadership sync', 'date': '04/11/2024', 'time': '2:00 PM', 'attendees': ['Alex', 'Olivia', 'Ryan'], 'location': 'Skype', 'duration': None, 'recurrence': None, 'notes': None}\n",
            "\n",
            "\n",
            "OUTPUT:\n",
            "-------\n",
            " {'action': 'leadership sync', 'date': '04/11/2024', 'time': '2:00 PM', 'attendees': ['Alex', 'Olivia', 'Ryan'], 'location': 'Skype', 'duration': None, 'recurrence': None, 'notes': None}\n",
            "------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "batch = next(iter(train_loader))\n",
        "print(\"BATCH KEYS:\")\n",
        "print(\"-\"*len(\"BATCH KEYS:\"))\n",
        "print(batch.keys())\n",
        "print(\"\\n\\n\")\n",
        "print(\"-\"*len(\"TRAINING BATCH EXAMPLE:  \"))\n",
        "print(\"SAMPLE BATCH EXAMPLES:\")\n",
        "print(\"-\"*len(\"TRAINING BATCH EXAMPLE:  \"))\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "\n",
        "for i in range(batch['input_ids'].shape[0]):\n",
        "    prompt_len = batch['prompt_len'][i].item()\n",
        "    input_text = tokenizer.decode(batch['input_ids'][i][0],skip_special_tokens=True)\n",
        "    label_text = tokenizer.decode(batch['labels'][i][0][prompt_len:],skip_special_tokens=True)\n",
        "\n",
        "    print(\"-\"*len(\"EXAMPLE:    \"))\n",
        "    print(f\"EXAMPLE: {i+1}\")\n",
        "    print(\"-\"*len(\"EXAMPLE:    \"))\n",
        "    print(f\"{input_text}\")\n",
        "    print(\"\\n\")\n",
        "    print(f\"OUTPUT:\")\n",
        "    print(\"-\"*len(\"OUTPUT:\"))\n",
        "    print(f\"{label_text}\")\n",
        "    print(\"-\"*60)\n",
        "    print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a10d3ac",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-27T00:34:30.435431Z",
          "iopub.status.busy": "2025-07-27T00:34:30.435217Z",
          "iopub.status.idle": "2025-07-27T00:34:30.708073Z",
          "shell.execute_reply": "2025-07-27T00:34:30.707298Z"
        },
        "papermill": {
          "duration": 0.30294,
          "end_time": "2025-07-27T00:34:30.709929",
          "exception": false,
          "start_time": "2025-07-27T00:34:30.406989",
          "status": "completed"
        },
        "tags": [],
        "id": "7a10d3ac",
        "outputId": "fbc9a672-ff9a-4026-9956-469451c94a9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss on Training Sample: 11.2001\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "batch = next(iter(train_loader))\n",
        "del batch['prompt_len']\n",
        "\n",
        "# ✅ Move batch tensors to same device\n",
        "batch = {k: v.to(device).squeeze(1) for k, v in batch.items()}\n",
        "\n",
        "output = model(**batch)\n",
        "loss = output.loss\n",
        "print(f\"Loss on Training Sample: {loss.item():.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f23d068",
      "metadata": {
        "papermill": {
          "duration": 0.028062,
          "end_time": "2025-07-27T00:34:30.767507",
          "exception": false,
          "start_time": "2025-07-27T00:34:30.739445",
          "status": "completed"
        },
        "tags": [],
        "id": "0f23d068"
      },
      "source": [
        "----------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "675347b9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-27T00:34:30.824119Z",
          "iopub.status.busy": "2025-07-27T00:34:30.823832Z",
          "iopub.status.idle": "2025-07-27T00:34:30.829691Z",
          "shell.execute_reply": "2025-07-27T00:34:30.829180Z"
        },
        "papermill": {
          "duration": 0.036265,
          "end_time": "2025-07-27T00:34:30.830768",
          "exception": false,
          "start_time": "2025-07-27T00:34:30.794503",
          "status": "completed"
        },
        "tags": [],
        "id": "675347b9"
      },
      "outputs": [],
      "source": [
        "def prepare_test_prompt(example):\n",
        "    example_prompt = {\n",
        "        \"event_text\": [example[\"event_text\"]],\n",
        "        \"output\": [\"\"]  # we don't use actual output at test time\n",
        "    }\n",
        "    prompt_data = serialize(example_prompt)\n",
        "    return prompt_data[\"text\"][0]  # return serialized string\n",
        "\n",
        "\n",
        "\n",
        "def tokenize_fn_val(example):\n",
        "\n",
        "    \"\"\"\n",
        "    Prepares tokenized input for supervised fine-tuning of a language model using prompt-response format.\n",
        "\n",
        "    This function takes a dictionary containing a prompt (`example[\"text\"]`) and a target output\n",
        "    (`example[\"output\"]`), concatenates them into a single training string, and tokenizes it using\n",
        "    the provided tokenizer. It ensures that only the target portion contributes to the training loss\n",
        "    by masking the prompt tokens with -100 in the label tensor.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    example : dict\n",
        "        A dictionary with:\n",
        "        - 'text': The input prompt string used to condition the model.\n",
        "        - 'output': The expected target string to be predicted by the model.\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    dict\n",
        "        A dictionary containing:\n",
        "        - 'input_ids': Token IDs of the concatenated prompt and target.\n",
        "        - 'attention_mask': Attention mask for the input sequence.\n",
        "        - 'labels': Token IDs with prompt tokens masked (-100) to compute loss only on the target.\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = prepare_test_prompt(example)\n",
        "    target = str(example.get(\"output\",\"\"))\n",
        "\n",
        "\n",
        "    # Concatenate prompt and expected output as training input\n",
        "    full_text = prompt + target\n",
        "    # print(f\"Full Text:\\n{full_text}\")\n",
        "\n",
        "\n",
        "    # Tokenize the full sequence\n",
        "    inputs = tokenizer(full_text, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=512)\n",
        "\n",
        "    input_ids = inputs[\"input_ids\"]\n",
        "    attention_mask = inputs[\"attention_mask\"]\n",
        "\n",
        "\n",
        "\n",
        "    # Create labels: only the target portion should contribute to loss\n",
        "    labels = input_ids.clone()\n",
        "    prompt_len = len(tokenizer(prompt)[\"input_ids\"])-1\n",
        "    labels[0,:prompt_len] = -100  # Mask out prompt tokens\n",
        "\n",
        "    # Final training batch\n",
        "    batch = {\n",
        "        \"input_ids\": input_ids.squeeze(1),\n",
        "        \"attention_mask\": attention_mask.squeeze(1),\n",
        "        \"labels\": labels.squeeze(1),\n",
        "        \"prompt_len\":prompt_len,\n",
        "\n",
        "    }\n",
        "\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a270dd17",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-27T00:34:30.887256Z",
          "iopub.status.busy": "2025-07-27T00:34:30.886805Z",
          "iopub.status.idle": "2025-07-27T00:34:31.074292Z",
          "shell.execute_reply": "2025-07-27T00:34:31.073580Z"
        },
        "papermill": {
          "duration": 0.217749,
          "end_time": "2025-07-27T00:34:31.076107",
          "exception": false,
          "start_time": "2025-07-27T00:34:30.858358",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "70f4f92585d14201a2d2087d10ddf180"
          ]
        },
        "id": "a270dd17",
        "outputId": "25c87db4-ea90-4ac2-a33d-fcc11277bfd0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70f4f92585d14201a2d2087d10ddf180",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/80 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenized_val = ds_val.map(tokenize_fn_val, remove_columns=ds_val.column_names)\n",
        "val_loader = DataLoader(tokenized_val, batch_size=4, shuffle=True, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d95b49c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-27T00:34:31.133886Z",
          "iopub.status.busy": "2025-07-27T00:34:31.133659Z",
          "iopub.status.idle": "2025-07-27T00:34:31.146065Z",
          "shell.execute_reply": "2025-07-27T00:34:31.145233Z"
        },
        "papermill": {
          "duration": 0.042658,
          "end_time": "2025-07-27T00:34:31.147262",
          "exception": false,
          "start_time": "2025-07-27T00:34:31.104604",
          "status": "completed"
        },
        "tags": [],
        "id": "4d95b49c",
        "outputId": "7172ded8-4673-4f2a-d901-72c0556473bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BATCH KEYS:\n",
            "-----------\n",
            "dict_keys(['input_ids', 'attention_mask', 'labels', 'prompt_len'])\n",
            "\n",
            "\n",
            "\n",
            "-------------------------\n",
            "SAMPLE BATCH EXAMPLES:\n",
            "-------------------------\n",
            "\n",
            "\n",
            "\n",
            "------------\n",
            "EXAMPLE: 1\n",
            "------------\n",
            "See the given example to extract the entities based on given input in JSON format.\n",
            "\n",
            "Example Input: Late night study session at the café on 15th, Dec 2024 at 9:00 pm for 2 hours.\n",
            "Example Output: {'action': 'study session', 'date': '15/12/2024', 'time': '9:00 PM', 'attendees': None, 'location': 'café', 'duration': '2 hours', 'recurrence': None, 'notes': None}\n",
            "--------------------------\n",
            "Please extract the entities for the below user input in JSON format. And do not output anything else.\n",
            "\n",
            "Human Input: Working session March 27, 2024 at 3pm, with Alice, Tanya, and Kay\n",
            "AI: {'action': 'Working session', 'date': '27/03/2024', 'time': '3:00 PM', 'attendees': ['Alice', 'Tanya', 'Kay'], 'location': None, 'duration': None, 'recurrence': None, 'notes': None}\n",
            "\n",
            "\n",
            "OUTPUT:\n",
            "-------\n",
            " {'action': 'Working session', 'date': '27/03/2024', 'time': '3:00 PM', 'attendees': ['Alice', 'Tanya', 'Kay'], 'location': None, 'duration': None, 'recurrence': None, 'notes': None}\n",
            "------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "------------\n",
            "EXAMPLE: 2\n",
            "------------\n",
            "See the given example to extract the entities based on given input in JSON format.\n",
            "\n",
            "Example Input: Late night study session at the café on 15th, Dec 2024 at 9:00 pm for 2 hours.\n",
            "Example Output: {'action': 'study session', 'date': '15/12/2024', 'time': '9:00 PM', 'attendees': None, 'location': 'café', 'duration': '2 hours', 'recurrence': None, 'notes': None}\n",
            "--------------------------\n",
            "Please extract the entities for the below user input in JSON format. And do not output anything else.\n",
            "\n",
            "Human Input: Schedule an awards ceremony rehearsal with Jack, Bella, and Ella on 15th, August 2026 at 1 PM in the auditorium for 2 hours.\n",
            "AI: {'action': 'Schedule an awards ceremony rehearsal', 'date': '15/08/2026', 'time': '1:00 PM', 'attendees': ['Jack', 'Bella', 'Ella'], 'location': 'auditorium', 'duration': '2 hours', 'recurrence': None, 'notes': None}\n",
            "\n",
            "\n",
            "OUTPUT:\n",
            "-------\n",
            " {'action': 'Schedule an awards ceremony rehearsal', 'date': '15/08/2026', 'time': '1:00 PM', 'attendees': ['Jack', 'Bella', 'Ella'], 'location': 'auditorium', 'duration': '2 hours', 'recurrence': None, 'notes': None}\n",
            "------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "------------\n",
            "EXAMPLE: 3\n",
            "------------\n",
            "See the given example to extract the entities based on given input in JSON format.\n",
            "\n",
            "Example Input: Late night study session at the café on 15th, Dec 2024 at 9:00 pm for 2 hours.\n",
            "Example Output: {'action': 'study session', 'date': '15/12/2024', 'time': '9:00 PM', 'attendees': None, 'location': 'café', 'duration': '2 hours', 'recurrence': None, 'notes': None}\n",
            "--------------------------\n",
            "Please extract the entities for the below user input in JSON format. And do not output anything else.\n",
            "\n",
            "Human Input: Catch up with marketing on June 2, 2024 at 14:00 for 45 minutes.\n",
            "AI: {'action': 'Catch up with marketing', 'date': '02/06/2024', 'time': '14:00', 'attendees': None, 'location': None, 'duration': '45 minutes', 'recurrence': None, 'notes': None}\n",
            "\n",
            "\n",
            "OUTPUT:\n",
            "-------\n",
            " {'action': 'Catch up with marketing', 'date': '02/06/2024', 'time': '14:00', 'attendees': None, 'location': None, 'duration': '45 minutes', 'recurrence': None, 'notes': None}\n",
            "------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "------------\n",
            "EXAMPLE: 4\n",
            "------------\n",
            "See the given example to extract the entities based on given input in JSON format.\n",
            "\n",
            "Example Input: Late night study session at the café on 15th, Dec 2024 at 9:00 pm for 2 hours.\n",
            "Example Output: {'action': 'study session', 'date': '15/12/2024', 'time': '9:00 PM', 'attendees': None, 'location': 'café', 'duration': '2 hours', 'recurrence': None, 'notes': None}\n",
            "--------------------------\n",
            "Please extract the entities for the below user input in JSON format. And do not output anything else.\n",
            "\n",
            "Human Input: Feedback chat March 11, 2024, 12:00 pm, 20 mins via Slack.\n",
            "AI: {'action': 'Feedback chat', 'date': '11/03/2024', 'time': '12:00 PM', 'attendees': None, 'location': 'Slack', 'duration': '20 mins', 'recurrence': None, 'notes': None}\n",
            "\n",
            "\n",
            "OUTPUT:\n",
            "-------\n",
            " {'action': 'Feedback chat', 'date': '11/03/2024', 'time': '12:00 PM', 'attendees': None, 'location': 'Slack', 'duration': '20 mins', 'recurrence': None, 'notes': None}\n",
            "------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "batch = next(iter(val_loader))\n",
        "print(\"BATCH KEYS:\")\n",
        "print(\"-\"*len(\"BATCH KEYS:\"))\n",
        "print(batch.keys())\n",
        "print(\"\\n\\n\")\n",
        "print(\"-\"*len(\"TRAINING BATCH EXAMPLE:  \"))\n",
        "print(\"SAMPLE BATCH EXAMPLES:\")\n",
        "print(\"-\"*len(\"TRAINING BATCH EXAMPLE:  \"))\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "\n",
        "for i in range(batch['input_ids'].shape[0]):\n",
        "    prompt_len = batch['prompt_len'][i].item()\n",
        "    input_text = tokenizer.decode(batch['input_ids'][i][0],skip_special_tokens=True)\n",
        "    label_text = tokenizer.decode(batch['labels'][i][0][prompt_len:],skip_special_tokens=True)\n",
        "\n",
        "    print(\"-\"*len(\"EXAMPLE:    \"))\n",
        "    print(f\"EXAMPLE: {i+1}\")\n",
        "    print(\"-\"*len(\"EXAMPLE:    \"))\n",
        "    print(f\"{input_text}\")\n",
        "    print(\"\\n\")\n",
        "    print(f\"OUTPUT:\")\n",
        "    print(\"-\"*len(\"OUTPUT:\"))\n",
        "    print(f\"{label_text}\")\n",
        "    print(\"-\"*60)\n",
        "    print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "042bffd0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-27T00:34:31.204522Z",
          "iopub.status.busy": "2025-07-27T00:34:31.204331Z",
          "iopub.status.idle": "2025-07-27T00:34:31.209630Z",
          "shell.execute_reply": "2025-07-27T00:34:31.208912Z"
        },
        "papermill": {
          "duration": 0.035031,
          "end_time": "2025-07-27T00:34:31.210660",
          "exception": false,
          "start_time": "2025-07-27T00:34:31.175629",
          "status": "completed"
        },
        "tags": [],
        "id": "042bffd0"
      },
      "outputs": [],
      "source": [
        "def compute_loss_on_val_set(model,data_loader,device):\n",
        "\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total_loss=0\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(data_loader,desc=\"Evaluating loss on entire set...\"):\n",
        "\n",
        "            del batch['prompt_len']\n",
        "\n",
        "            # ✅ Move batch tensors to same device\n",
        "            batch = {k: v.to(device).squeeze(1) for k, v in batch.items()}\n",
        "\n",
        "            output = model(**batch)\n",
        "            batch_loss = output.loss\n",
        "\n",
        "            total_loss+=batch_loss\n",
        "\n",
        "\n",
        "    return total_loss.item() / data_loader.__len__()\n",
        "\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "085508e7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-27T00:34:31.267872Z",
          "iopub.status.busy": "2025-07-27T00:34:31.267654Z",
          "iopub.status.idle": "2025-07-27T00:34:57.033597Z",
          "shell.execute_reply": "2025-07-27T00:34:57.032651Z"
        },
        "papermill": {
          "duration": 25.796159,
          "end_time": "2025-07-27T00:34:57.034820",
          "exception": false,
          "start_time": "2025-07-27T00:34:31.238661",
          "status": "completed"
        },
        "tags": [],
        "id": "085508e7",
        "outputId": "0e8f071c-661d-4f7c-a084-5f81ea61f080"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating loss on entire set...: 100%|██████████| 178/178 [00:23<00:00,  7.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11.129414419109901\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating loss on entire set...: 100%|██████████| 20/20 [00:02<00:00,  7.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11.20376968383789\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print(compute_loss_on_val_set(model,train_loader,device))\n",
        "print(compute_loss_on_val_set(model,val_loader,device))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0e3c004",
      "metadata": {
        "papermill": {
          "duration": 0.035023,
          "end_time": "2025-07-27T00:34:57.107667",
          "exception": false,
          "start_time": "2025-07-27T00:34:57.072644",
          "status": "completed"
        },
        "tags": [],
        "id": "e0e3c004"
      },
      "source": [
        "## Setting up PEFT config..!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94a14be3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-27T00:34:57.179676Z",
          "iopub.status.busy": "2025-07-27T00:34:57.179446Z",
          "iopub.status.idle": "2025-07-27T00:34:57.275866Z",
          "shell.execute_reply": "2025-07-27T00:34:57.275090Z"
        },
        "papermill": {
          "duration": 0.133918,
          "end_time": "2025-07-27T00:34:57.277066",
          "exception": false,
          "start_time": "2025-07-27T00:34:57.143148",
          "status": "completed"
        },
        "tags": [],
        "id": "94a14be3",
        "outputId": "1a17ca71-5cd6-4672-a478-dc0ed93f9bd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 1,638,400 || all params: 363,459,520 || trainable%: 0.4508\n"
          ]
        }
      ],
      "source": [
        "peft_model = prepare_model_for_kbit_training(model)\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    inference_mode=False,\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.05,\n",
        "    target_modules=[\"q_proj\", \"v_proj\"],\n",
        ")\n",
        "\n",
        "peft_model = get_peft_model(peft_model, lora_config)\n",
        "\n",
        "peft_model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07b2a69a",
      "metadata": {
        "papermill": {
          "duration": 0.036202,
          "end_time": "2025-07-27T00:34:57.349582",
          "exception": false,
          "start_time": "2025-07-27T00:34:57.313380",
          "status": "completed"
        },
        "tags": [],
        "id": "07b2a69a"
      },
      "source": [
        "## Getting started with Training Loop..!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ce4c5b6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-27T00:34:57.421238Z",
          "iopub.status.busy": "2025-07-27T00:34:57.420509Z",
          "iopub.status.idle": "2025-07-27T01:13:41.899729Z",
          "shell.execute_reply": "2025-07-27T01:13:41.898842Z"
        },
        "papermill": {
          "duration": 2324.516033,
          "end_time": "2025-07-27T01:13:41.900938",
          "exception": false,
          "start_time": "2025-07-27T00:34:57.384905",
          "status": "completed"
        },
        "tags": [],
        "id": "5ce4c5b6",
        "outputId": "daaebff0-7e4f-4257-d63b-a1fbe970f044"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------\n",
            "TRAINING LOOP BEGINS:\n",
            "-----------------------\n",
            "\n",
            "🔁 Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:   0%|          | 0/178 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "Epoch 1:  28%|██▊       | 50/178 [00:46<01:59,  1.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Step 50, Loss: 0.2387\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  56%|█████▌    | 100/178 [01:34<01:14,  1.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Step 100, Loss: 0.0395\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  84%|████████▍ | 150/178 [02:22<00:27,  1.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Step 150, Loss: 0.0323\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|██████████| 178/178 [02:49<00:00,  1.05it/s]\n",
            "Evaluating loss on entire set...: 100%|██████████| 178/178 [00:48<00:00,  3.69it/s]\n",
            "Evaluating loss on entire set...: 100%|██████████| 20/20 [00:05<00:00,  3.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Epoch 1 completed. Avg Trainig Loss: 0.0229. Avg Val Loss: 0.0219\n",
            "\n",
            "🔁 Epoch 2/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  12%|█▏        | 22/178 [00:21<02:33,  1.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Step 200, Loss: 0.0180\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  40%|████      | 72/178 [01:11<01:45,  1.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Step 250, Loss: 0.0262\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  69%|██████▊   | 122/178 [02:00<00:55,  1.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Step 300, Loss: 0.0088\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  97%|█████████▋| 172/178 [02:50<00:05,  1.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Step 350, Loss: 0.0067\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|██████████| 178/178 [02:56<00:00,  1.01it/s]\n",
            "Evaluating loss on entire set...: 100%|██████████| 178/178 [00:49<00:00,  3.61it/s]\n",
            "Evaluating loss on entire set...: 100%|██████████| 20/20 [00:05<00:00,  3.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Epoch 2 completed. Avg Trainig Loss: 0.0107. Avg Val Loss: 0.0116\n",
            "\n",
            "🔁 Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  25%|██▍       | 44/178 [00:43<02:12,  1.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Step 400, Loss: 0.0069\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  53%|█████▎    | 94/178 [01:33<01:23,  1.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Step 450, Loss: 0.0085\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  81%|████████  | 144/178 [02:22<00:33,  1.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Step 500, Loss: 0.0127\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3: 100%|██████████| 178/178 [02:56<00:00,  1.01it/s]\n",
            "Evaluating loss on entire set...: 100%|██████████| 178/178 [00:49<00:00,  3.60it/s]\n",
            "Evaluating loss on entire set...: 100%|██████████| 20/20 [00:05<00:00,  3.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Epoch 3 completed. Avg Trainig Loss: 0.0066. Avg Val Loss: 0.0079\n",
            "\n",
            "🔁 Epoch 4/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:   9%|▉         | 16/178 [00:15<02:40,  1.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Step 550, Loss: 0.0052\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  37%|███▋      | 66/178 [01:05<01:50,  1.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Step 600, Loss: 0.0088\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  65%|██████▌   | 116/178 [01:54<01:01,  1.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Step 650, Loss: 0.0020\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  93%|█████████▎| 166/178 [02:44<00:11,  1.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Step 700, Loss: 0.0032\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4: 100%|██████████| 178/178 [02:56<00:00,  1.01it/s]\n",
            "Evaluating loss on entire set...: 100%|██████████| 178/178 [00:49<00:00,  3.59it/s]\n",
            "Evaluating loss on entire set...: 100%|██████████| 20/20 [00:05<00:00,  3.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Epoch 4 completed. Avg Trainig Loss: 0.0050. Avg Val Loss: 0.0065\n",
            "\n",
            "🔁 Epoch 5/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  21%|██▏       | 38/178 [00:37<02:20,  1.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Step 750, Loss: 0.0073\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  49%|████▉     | 88/178 [01:28<01:30,  1.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Step 800, Loss: 0.0024\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  78%|███████▊  | 138/178 [02:18<00:40,  1.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Step 850, Loss: 0.0029\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5: 100%|██████████| 178/178 [02:58<00:00,  1.01s/it]\n",
            "Evaluating loss on entire set...: 100%|██████████| 178/178 [00:50<00:00,  3.53it/s]\n",
            "Evaluating loss on entire set...: 100%|██████████| 20/20 [00:05<00:00,  3.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Epoch 5 completed. Avg Trainig Loss: 0.0039. Avg Val Loss: 0.0057\n",
            "\n",
            "🔁 Epoch 6/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6:   6%|▌         | 10/178 [00:10<02:49,  1.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Step 900, Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6:  34%|███▎      | 60/178 [01:00<01:59,  1.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Step 950, Loss: 0.0035\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6:  62%|██████▏   | 110/178 [01:51<01:08,  1.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Step 1000, Loss: 0.0019\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6:  90%|████████▉ | 160/178 [02:41<00:18,  1.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Step 1050, Loss: 0.0029\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6: 100%|██████████| 178/178 [02:59<00:00,  1.01s/it]\n",
            "Evaluating loss on entire set...: 100%|██████████| 178/178 [00:50<00:00,  3.52it/s]\n",
            "Evaluating loss on entire set...: 100%|██████████| 20/20 [00:05<00:00,  3.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Epoch 6 completed. Avg Trainig Loss: 0.0040. Avg Val Loss: 0.0070\n",
            "\n",
            "🔁 Epoch 7/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7:  18%|█▊        | 32/178 [00:32<02:27,  1.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Step 1100, Loss: 0.0035\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7:  46%|████▌     | 82/178 [01:22<01:36,  1.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Step 1150, Loss: 0.0092\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7:  74%|███████▍  | 132/178 [02:13<00:46,  1.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Step 1200, Loss: 0.0015\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7: 100%|██████████| 178/178 [02:59<00:00,  1.01s/it]\n",
            "Evaluating loss on entire set...: 100%|██████████| 178/178 [00:50<00:00,  3.53it/s]\n",
            "Evaluating loss on entire set...: 100%|██████████| 20/20 [00:05<00:00,  3.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Epoch 7 completed. Avg Trainig Loss: 0.0024. Avg Val Loss: 0.0051\n",
            "\n",
            "🔁 Epoch 8/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8:   2%|▏         | 4/178 [00:04<02:55,  1.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Step 1250, Loss: 0.0006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8:  30%|███       | 54/178 [00:54<02:05,  1.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Step 1300, Loss: 0.0009\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8:  58%|█████▊    | 104/178 [01:45<01:14,  1.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Step 1350, Loss: 0.0021\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8:  87%|████████▋ | 154/178 [02:35<00:24,  1.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Step 1400, Loss: 0.0013\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8: 100%|██████████| 178/178 [02:59<00:00,  1.01s/it]\n",
            "Evaluating loss on entire set...: 100%|██████████| 178/178 [00:50<00:00,  3.56it/s]\n",
            "Evaluating loss on entire set...: 100%|██████████| 20/20 [00:05<00:00,  3.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Epoch 8 completed. Avg Trainig Loss: 0.0032. Avg Val Loss: 0.0067\n",
            "\n",
            "🔁 Epoch 9/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9:  15%|█▍        | 26/178 [00:25<02:31,  1.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Step 1450, Loss: 0.0018\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9:  43%|████▎     | 76/178 [01:15<01:41,  1.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Step 1500, Loss: 0.0026\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9:  71%|███████   | 126/178 [02:05<00:51,  1.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Step 1550, Loss: 0.0014\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9:  99%|█████████▉| 176/178 [02:54<00:01,  1.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Step 1600, Loss: 0.0007\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9: 100%|██████████| 178/178 [02:56<00:00,  1.01it/s]\n",
            "Evaluating loss on entire set...: 100%|██████████| 178/178 [00:49<00:00,  3.59it/s]\n",
            "Evaluating loss on entire set...: 100%|██████████| 20/20 [00:05<00:00,  3.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Epoch 9 completed. Avg Trainig Loss: 0.0016. Avg Val Loss: 0.0049\n",
            "\n",
            "🔁 Epoch 10/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10:  27%|██▋       | 48/178 [00:47<02:08,  1.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Step 1650, Loss: 0.0093\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10:  55%|█████▌    | 98/178 [01:36<01:19,  1.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Step 1700, Loss: 0.0038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10:  83%|████████▎ | 148/178 [02:26<00:29,  1.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Step 1750, Loss: 0.0022\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10: 100%|██████████| 178/178 [02:56<00:00,  1.01it/s]\n",
            "Evaluating loss on entire set...: 100%|██████████| 178/178 [00:49<00:00,  3.59it/s]\n",
            "Evaluating loss on entire set...: 100%|██████████| 20/20 [00:05<00:00,  3.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Epoch 10 completed. Avg Trainig Loss: 0.0013. Avg Val Loss: 0.0049\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "accelerator = Accelerator(cpu=False, split_batches=False)\n",
        "peft_model = accelerator.prepare(peft_model)\n",
        "batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "peft_model = peft_model.to(device)\n",
        "\n",
        "optimizer = AdamW(peft_model.parameters(), lr=2e-4)\n",
        "\n",
        "epochs = 10\n",
        "step_count = 0\n",
        "\n",
        "loss_metric = {}\n",
        "loss_metric['train_loss']=[]\n",
        "loss_metric['val_loss']=[]\n",
        "\n",
        "print(\"-\"*len(\"TRAINING LOOP BEGINS:  \"))\n",
        "print(\"TRAINING LOOP BEGINS:\")\n",
        "print(\"-\"*len(\"TRAINING LOOP BEGINS:  \"))\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    peft_model.train()\n",
        "    epoch_loss = 0.0\n",
        "    print(f\"\\n🔁 Epoch {epoch+1}/{epochs}\")\n",
        "\n",
        "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
        "        del batch['prompt_len']\n",
        "        batch = {k: v.to(device).squeeze(1) for k, v in batch.items()}\n",
        "\n",
        "\n",
        "        outputs = peft_model(**batch)\n",
        "\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        step_count += 1\n",
        "\n",
        "        if step_count % 50 == 0:\n",
        "            print(f\"🔹 Step {step_count}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "    avg_loss = compute_loss_on_val_set(peft_model,train_loader,device)\n",
        "    avg_val_loss = compute_loss_on_val_set(peft_model,val_loader,device)\n",
        "\n",
        "    print(f\"✅ Epoch {epoch+1} completed. Avg Trainig Loss: {avg_loss:.4f}. Avg Val Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "    loss_metric['train_loss'].append(avg_loss)\n",
        "    loss_metric['val_loss'].append(avg_val_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a26b79ba",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-27T01:13:42.281414Z",
          "iopub.status.busy": "2025-07-27T01:13:42.280697Z",
          "iopub.status.idle": "2025-07-27T01:13:42.649198Z",
          "shell.execute_reply": "2025-07-27T01:13:42.648458Z"
        },
        "papermill": {
          "duration": 0.556387,
          "end_time": "2025-07-27T01:13:42.650443",
          "exception": false,
          "start_time": "2025-07-27T01:13:42.094056",
          "status": "completed"
        },
        "tags": [],
        "id": "a26b79ba",
        "outputId": "73e3f1bf-8675-4dec-afa5-bc02187bd59a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "x = [i for i in range(len(loss_metric['train_loss']))]\n",
        "plt.plot(x,loss_metric['train_loss'])\n",
        "plt.plot(x,loss_metric['val_loss'])\n",
        "plt.legend(['Train','Val'])\n",
        "plt.xlabel('No. of Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37b00a15",
      "metadata": {
        "papermill": {
          "duration": 0.187464,
          "end_time": "2025-07-27T01:13:43.027298",
          "exception": false,
          "start_time": "2025-07-27T01:13:42.839834",
          "status": "completed"
        },
        "tags": [],
        "id": "37b00a15"
      },
      "source": [
        "## Checking performance for the NER task..!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdc89151",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-27T01:13:43.453813Z",
          "iopub.status.busy": "2025-07-27T01:13:43.453311Z",
          "iopub.status.idle": "2025-07-27T01:13:43.459382Z",
          "shell.execute_reply": "2025-07-27T01:13:43.458693Z"
        },
        "papermill": {
          "duration": 0.246436,
          "end_time": "2025-07-27T01:13:43.460514",
          "exception": false,
          "start_time": "2025-07-27T01:13:43.214078",
          "status": "completed"
        },
        "tags": [],
        "id": "fdc89151"
      },
      "outputs": [],
      "source": [
        "def compare_dicts(result_dict, output_dict):\n",
        "    comparison = {}\n",
        "    for key in output_dict.keys():\n",
        "        expected = output_dict[key]\n",
        "        predicted = result_dict.get(key, None)\n",
        "\n",
        "        # Normalize string values\n",
        "        if isinstance(expected, str) and isinstance(predicted, str):\n",
        "            expected = expected.strip().lower()\n",
        "            predicted = predicted.strip().lower()\n",
        "\n",
        "        # For lists: compare ignoring order\n",
        "        if isinstance(expected, list) and isinstance(predicted, list):\n",
        "            correct = sorted(expected) == sorted(predicted)\n",
        "        else:\n",
        "            correct = expected == predicted\n",
        "\n",
        "        comparison[key] = {\n",
        "            \"expected\": output_dict[key],\n",
        "            \"predicted\": result_dict.get(key, None),\n",
        "            \"match\": correct\n",
        "        }\n",
        "\n",
        "    return comparison\n",
        "\n",
        "def dict_accuracy(result_dict, output_dict):\n",
        "    comp = compare_dicts(result_dict, output_dict)\n",
        "    matches = sum(1 for k in comp if comp[k]['match'])\n",
        "    acc = {key: int(comp[key][\"match\"]) for key in comp}\n",
        "    return acc\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd56bd60",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-27T01:13:43.845088Z",
          "iopub.status.busy": "2025-07-27T01:13:43.844705Z",
          "iopub.status.idle": "2025-07-27T01:13:43.850150Z",
          "shell.execute_reply": "2025-07-27T01:13:43.849445Z"
        },
        "papermill": {
          "duration": 0.201084,
          "end_time": "2025-07-27T01:13:43.851362",
          "exception": false,
          "start_time": "2025-07-27T01:13:43.650278",
          "status": "completed"
        },
        "tags": [],
        "id": "bd56bd60"
      },
      "outputs": [],
      "source": [
        "def run_generation(model, tokenizer, example):\n",
        "    model.eval()\n",
        "    prompt = prepare_test_prompt(example)\n",
        "    # print(prompt)\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "    input_length = inputs[\"input_ids\"].shape[-1]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output_ids = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=512,\n",
        "            do_sample=False,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    # Get generated text *excluding* the input\n",
        "    generated_ids = output_ids[:, input_length:]\n",
        "    decoded = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    try:\n",
        "        result_dict = ast.literal_eval(decoded.strip())\n",
        "    except Exception as e:\n",
        "        result_dict = {\"error\": str(e), \"raw_output\": decoded}\n",
        "\n",
        "    return result_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b99abb1d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-27T01:13:44.240059Z",
          "iopub.status.busy": "2025-07-27T01:13:44.239480Z",
          "iopub.status.idle": "2025-07-27T01:13:50.483721Z",
          "shell.execute_reply": "2025-07-27T01:13:50.482864Z"
        },
        "papermill": {
          "duration": 6.435579,
          "end_time": "2025-07-27T01:13:50.485244",
          "exception": false,
          "start_time": "2025-07-27T01:13:44.049665",
          "status": "completed"
        },
        "tags": [],
        "id": "b99abb1d",
        "outputId": "a974944e-4fb4-4051-edeb-744bf564ec99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted: {'action': 'Cycling', 'date': '20/03/2024', 'time': '6:00 AM', 'attendees': ['Luke'], 'location': 'Riverside Park', 'duration': '45 mins', 'recurrence': None, 'notes': None}\n",
            "Actual: {'action': 'Cycling', 'date': '20/03/2024', 'time': '6:00 AM', 'attendees': ['Luke'], 'location': 'Riverside Park', 'duration': '45 mins', 'recurrence': None, 'notes': None}\n"
          ]
        }
      ],
      "source": [
        "example = ds_train[1]\n",
        "predicted_dict = run_generation(peft_model, tokenizer, example)\n",
        "\n",
        "print(\"Predicted:\", predicted_dict)\n",
        "print(\"Actual:\", example[\"output\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d56c2c0",
      "metadata": {
        "papermill": {
          "duration": 0.243599,
          "end_time": "2025-07-27T01:13:50.918255",
          "exception": false,
          "start_time": "2025-07-27T01:13:50.674656",
          "status": "completed"
        },
        "tags": [],
        "id": "0d56c2c0"
      },
      "source": [
        "### Saving the model and tokenizer..!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e50cf689",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-27T01:13:51.294636Z",
          "iopub.status.busy": "2025-07-27T01:13:51.294356Z",
          "iopub.status.idle": "2025-07-27T01:13:52.455622Z",
          "shell.execute_reply": "2025-07-27T01:13:52.454860Z"
        },
        "papermill": {
          "duration": 1.351683,
          "end_time": "2025-07-27T01:13:52.457122",
          "exception": false,
          "start_time": "2025-07-27T01:13:51.105439",
          "status": "completed"
        },
        "tags": [],
        "id": "e50cf689",
        "outputId": "d02811a8-e1ed-4731-e62e-68ae6a3d4e42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tar: Removing leading `/' from member names\r\n",
            "/kaggle/working/lora-ner-model/\r\n",
            "/kaggle/working/lora-ner-model/adapter_config.json\r\n",
            "/kaggle/working/lora-ner-model/special_tokens_map.json\r\n",
            "/kaggle/working/lora-ner-model/adapter_model.safetensors\r\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/kaggle/working/lora-ner-model/tokenizer_config.json\r\n",
            "/kaggle/working/lora-ner-model/merges.txt\r\n",
            "/kaggle/working/lora-ner-model/vocab.json\r\n",
            "/kaggle/working/lora-ner-model/README.md\r\n",
            "/kaggle/working/lora-ner-model/tokenizer.json\r\n"
          ]
        }
      ],
      "source": [
        "peft_model.save_pretrained(\"lora-ner-model\")\n",
        "tokenizer.save_pretrained(\"lora-ner-model\")\n",
        "\n",
        "!tar -zcvf lora-ner-model.tar.gz /kaggle/working/lora-ner-model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31e235f3",
      "metadata": {
        "papermill": {
          "duration": 0.18796,
          "end_time": "2025-07-27T01:13:52.832759",
          "exception": false,
          "start_time": "2025-07-27T01:13:52.644799",
          "status": "completed"
        },
        "tags": [],
        "id": "31e235f3"
      },
      "source": [
        "### Calculating accuracy for NER task..!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6cc5cbc",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-27T01:13:53.215219Z",
          "iopub.status.busy": "2025-07-27T01:13:53.214877Z",
          "iopub.status.idle": "2025-07-27T02:26:49.986244Z",
          "shell.execute_reply": "2025-07-27T02:26:49.984917Z"
        },
        "papermill": {
          "duration": 4376.966167,
          "end_time": "2025-07-27T02:26:49.987401",
          "exception": false,
          "start_time": "2025-07-27T01:13:53.021234",
          "status": "completed"
        },
        "tags": [],
        "id": "f6cc5cbc",
        "outputId": "3dc4fff3-6635-4026-97d2-5e894d6fe5cf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 712/712 [1:12:56<00:00,  6.15s/it]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "comp = ast.literal_eval(ds_train[0]['output']).keys()\n",
        "\n",
        "result_df = {}\n",
        "for i in tqdm(range(ds_train.__len__())):\n",
        "    example = ds_train[i]\n",
        "    predicted_dict = run_generation(peft_model, tokenizer, example)\n",
        "    example['output'] = ast.literal_eval(example['output'])\n",
        "    matches = dict_accuracy(predicted_dict,example['output'])\n",
        "\n",
        "    for com in comp:\n",
        "        if com in result_df.keys():\n",
        "            result_df[com].append(matches[com])\n",
        "        else:\n",
        "            result_df[com]=[]\n",
        "            result_df[com].append(matches[com])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3adc64e5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-27T02:26:50.423300Z",
          "iopub.status.busy": "2025-07-27T02:26:50.422998Z",
          "iopub.status.idle": "2025-07-27T02:26:50.503268Z",
          "shell.execute_reply": "2025-07-27T02:26:50.502508Z"
        },
        "papermill": {
          "duration": 0.298682,
          "end_time": "2025-07-27T02:26:50.504454",
          "exception": false,
          "start_time": "2025-07-27T02:26:50.205772",
          "status": "completed"
        },
        "tags": [],
        "id": "3adc64e5",
        "outputId": "97c49ca9-13c2-4b68-fad5-b46c34185a77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average accuracy for each `NER` on training set..!\n",
            "\n",
            "\n",
            "action        0.978933\n",
            "date          0.987360\n",
            "time          0.994382\n",
            "attendees     0.994382\n",
            "location      0.991573\n",
            "duration      0.985955\n",
            "recurrence    0.997191\n",
            "notes         0.983146\n",
            "Name: mean, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "result_df = pd.DataFrame(result_df)\n",
        "print(\"Average accuracy for each `NER` on training set..!\")\n",
        "print(\"\\n\")\n",
        "print(result_df.describe().loc['mean'])\n",
        "result_df.to_csv('Train_Error.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "294f1b97",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-27T02:26:51.000285Z",
          "iopub.status.busy": "2025-07-27T02:26:50.999592Z",
          "iopub.status.idle": "2025-07-27T02:34:55.404687Z",
          "shell.execute_reply": "2025-07-27T02:34:55.403879Z"
        },
        "papermill": {
          "duration": 484.624359,
          "end_time": "2025-07-27T02:34:55.405770",
          "exception": false,
          "start_time": "2025-07-27T02:26:50.781411",
          "status": "completed"
        },
        "tags": [],
        "id": "294f1b97",
        "outputId": "68401f88-053f-469e-8763-d7be3e49267d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 80/80 [08:04<00:00,  6.05s/it]\n"
          ]
        }
      ],
      "source": [
        "comp = ast.literal_eval(ds_train[0]['output']).keys()\n",
        "\n",
        "result_df = {}\n",
        "for i in tqdm(range(ds_val.__len__())):\n",
        "    example = ds_val[i]\n",
        "    predicted_dict = run_generation(peft_model, tokenizer, example)\n",
        "    # example['output'] = ast.literal_eval(example['output'])\n",
        "    matches = dict_accuracy(predicted_dict,example['output'])\n",
        "\n",
        "    for com in comp:\n",
        "        if com in result_df.keys():\n",
        "            result_df[com].append(matches[com])\n",
        "        else:\n",
        "            result_df[com]=[]\n",
        "            result_df[com].append(matches[com])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99af7936",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-27T02:34:55.853322Z",
          "iopub.status.busy": "2025-07-27T02:34:55.852865Z",
          "iopub.status.idle": "2025-07-27T02:34:55.871217Z",
          "shell.execute_reply": "2025-07-27T02:34:55.870450Z"
        },
        "papermill": {
          "duration": 0.24314,
          "end_time": "2025-07-27T02:34:55.872536",
          "exception": false,
          "start_time": "2025-07-27T02:34:55.629396",
          "status": "completed"
        },
        "tags": [],
        "id": "99af7936",
        "outputId": "84d524e9-4b57-4cd8-b3fd-a70e318394e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average accuracy for each `NER` on validation set..!\n",
            "\n",
            "\n",
            "action        0.8875\n",
            "date          0.9625\n",
            "time          0.9875\n",
            "attendees     0.9875\n",
            "location      0.9500\n",
            "duration      0.9750\n",
            "recurrence    1.0000\n",
            "notes         0.9375\n",
            "Name: mean, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "result_df = pd.DataFrame(result_df)\n",
        "print(\"Average accuracy for each `NER` on validation set..!\")\n",
        "print(\"\\n\")\n",
        "print(result_df.describe().loc['mean'])\n",
        "result_df.to_csv('Val_Error.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e04124b",
      "metadata": {
        "papermill": {
          "duration": 0.223746,
          "end_time": "2025-07-27T02:34:56.328118",
          "exception": false,
          "start_time": "2025-07-27T02:34:56.104372",
          "status": "completed"
        },
        "tags": [],
        "id": "8e04124b"
      },
      "source": [
        "-------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c09a08a2",
      "metadata": {
        "papermill": {
          "duration": 0.218845,
          "end_time": "2025-07-27T02:34:56.828801",
          "exception": false,
          "start_time": "2025-07-27T02:34:56.609956",
          "status": "completed"
        },
        "tags": [],
        "id": "c09a08a2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 7941971,
          "sourceId": 12575520,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31090,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 7392.703393,
      "end_time": "2025-07-27T02:35:00.763166",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-07-27T00:31:48.059773",
      "version": "2.6.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}